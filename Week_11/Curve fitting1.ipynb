{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve fitting\n",
    "In this notebook, we will explore the use of some python functions to fit nonlinear functions (such as Gaussian, sine, or polynomial functions) to data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Curve fitting optimization\n",
    "from scipy import optimize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: generate some data. \n",
    "To explore model fitting, we need to have some data with a true function underlying it. Let's use a Gaussian, because (a) many phenomena in the world are well modeled by Gaussian functions, and (b) we have used Gaussians a bunch already in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a function to define a 1D Gaussian curve:\n",
    "def gauss(x, mu, sigma, amp=1):\n",
    "    \"\"\"Estimate value of Gaussian function for specific value or values of x\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : scalar or array-like\n",
    "        value or values at which to evaluate the Gaussian\n",
    "    mu : scalar\n",
    "        mean of Gaussian\n",
    "    sigma : scalar\n",
    "        std of Gaussian\n",
    "    amp : amplitude of Gaussian\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    valueof Gaussian at `x`\n",
    "    \"\"\"\n",
    "    return amp * np.e**(-(x-mu)**2 / (2*sigma))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generate some data for a Gaussian with some particular mean and standard deviation. \n",
    "\n",
    "Pick a `mu` and `sigma` value, and decide which X values should you use. Define `y` as the output of the plot `x` against the output ofthe g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "n = 101 # number of data points\n",
    "mu = 0.5 # mean of the true Gaussian function\n",
    "sigma = 0.5 # standard deviation of the true Gaussian function\n",
    "# Generate some random input values for the input to the Gaussian\n",
    "x = np.random.uniform(low=-3, high=3, size=(n,))\n",
    "# Generate perfect data (that is exactly the output of a Gaussian function of x)\n",
    "y_perfect = gauss(x, mu=mu, sigma=sigma, amp=1)\n",
    "# Add some random normal (i.e., Gaussian...) noise\n",
    "noise = np.random.normal(loc=0, scale=0.2, size=y_perfect.shape)\n",
    "y = y_perfect + noise\n",
    "# Plot the result\n",
    "plt.scatter(x, y,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: use `scipy.optimize.curve_fit()` to estimate the parameters ($\\mu$, $\\sigma$) of the underlying Gaussian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inputs to the curve fitting function are:\n",
    "params, params_covariance = optimize.curve_fit(gauss, # The executable function to be fit\n",
    "                                               x, # The observed (here, simulated) input data to the function\n",
    "                                               y, # The observed (here, simulated) output from the function\n",
    "                                               p0=None # initial guesses as to parameter values. \n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the initial guesses are not critically important for this first fit, but we will see later how they can be very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `params` output contains the estimates for mu and sigma (and amp, technically)\n",
    "mu_est, sigma_est, amp_est = params\n",
    "# Print out formatted output (this syntax is very similar to matlab's sprintf function... worth knowing)\n",
    "print('real mu: %0.3f, estimated mu: %0.3f'%(mu, mu_est))\n",
    "print('real sigma: %0.3f, estimated sigma: %0.3f'%(sigma, sigma_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Now, we can use the estimated values to make predictions of the data we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_within_set = gauss(x, mu_est, sigma_est, amp_est)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x, ypred_within_set, '.', color='orange')\n",
    "ax.set_title(\"Within-set prediction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to go is to fit NEW data. To plot a pretty curve, let's compute the expected function output for some x values that are very regular - say, linearly spaced over the original range of our data. Technically, this is predicting out of set to new data that we didn't use to fit the model. We don't have out-of-set y data yet, though we could generate some... (that's left as an exercise to you). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(-3, 3, 101)\n",
    "y_test_gauss = gauss(x_test, mu_est, sigma_est)\n",
    "# and plot it\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x_test, y_test_gauss, '-', color='orange')\n",
    "ax.set_title(\"General prediction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting other functions \n",
    "Now let's fit a sine curve to the same data, just for giggles. To do this, we need to define a parametric sine function with parameters for the frequency and phase of the sine curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine function\n",
    "def sinx(x, freq, phase, amp=1.0):\n",
    "    y = np.sin(x * 2 * np.pi * freq + phase) * amp\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit this function to the data the same way!\n",
    "# Note that the input function changed from `gauss` to `sinx`, but all else (input, output data) is the same as above.\n",
    "params_sin, params_covariance_sin = optimize.curve_fit(sinx, x, y, p0=None)\n",
    "# Extract the parameters\n",
    "freq_est, phase_est, amp_est = params_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "x_test = np.linspace(-3, 3, 101)\n",
    "y_test_sin = sinx(x_test, freq_est, phase_est)\n",
    "# and plot it\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x_test, y_test_sin, '-', color='orange')\n",
    "ax.set_title(\"General prediction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oopsies! that didn't go so well. Let's try incorporating an educated guess about the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0 is your guess for the (freq, phase, amp) parameters\n",
    "freq_guess = 1/6 # This is in cycles per unit of the graph. So, probably << 1, since there is only about one cycle\n",
    "               # for 6 total units of X. Let's try 1/6!\n",
    "phase_guess = 0.2 # phase varies from 0-2pi. This may need to be adjusted.\n",
    "amp_guess = 1 # stick with 1\n",
    "params_sin, params_covariance_sin = optimize.curve_fit(sinx, x, y, p0=(freq_guess, phase_guess, amp_guess))\n",
    "# Extract the parameters\n",
    "freq_est, phase_est, amp_est = params_sin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to plot again\n",
    "x_test = np.linspace(-3, 3, 101)\n",
    "y_test_sin = sinx(x_test, freq_est, phase_est)\n",
    "# and plot it\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x_test, y_test_sin, '-', color='orange')\n",
    "ax.set_title(\"General prediction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! Run the cell several times with different initial guesses, see how different estimates will lead to different predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation 2, part 2a:\n",
    "> Fit a simple quadratic function to the same data. \n",
    "\n",
    "The equation for a quadratic is $f(x) = ax^2 + b$\n",
    "\n",
    "$a$ and $b$ are the parameters to be estimated. \n",
    "\n",
    "Estimate $a$ and $b$ using `optimize.curve_fit()`, and use the resulting parameter estimates to plot the predictions of the quadratic model to the data, as we did for the sin model in the cell(s) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 2, part 2b:\n",
    "Choose ONE of the following problems (A or B) to solve. For this, your code must RUN.\n",
    "\n",
    "> A. Generate simulated (noisy) 2D Gaussian data. You will have to choose true parameters for the 2D Gaussian function ($mu_x$, $mu_y$, and $sigma$). Then use `optimize.curve_fit()` to recover estimates for the true parameters for the data, as we did above. Display the estimates for the parameters and the true parameters together. For bonus points, use the estimated parameters to generate a 2D Gaussian image, and display it. \n",
    "\n",
    "Use this function for generating a 2D gaussian:\n",
    "```python\n",
    "def gauss2d(xy, mu_x, mu_y, sigma, amp=1):\n",
    "    \"\"\"Generate a spherical 2D Gaussian function\"\"\"\n",
    "    x, y = xy\n",
    "    g = amp * np.e**(-((x - mu_x)**2 + (y - mu_y)**2) / (2 * sigma**2))\n",
    "    return g\n",
    "```\n",
    "\n",
    "> B. Evaluate the error for the Gaussian, sine, and quadratic functions on the original data. The error is the sum of squared differences between the data and the within-set predictions. Show which function has the lowest error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
